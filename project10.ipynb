{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKEhT0owQaIY9hRk1XmXhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sk643666/AIFFEL_quest_cr/blob/master/project10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--SkyLVc1x4l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "path = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(path, 'train')\n",
        "validation_dir = os.path.join(path, 'validation')\n",
        "print(train_dir)\n",
        "print(validation_dir)\n",
        "\n",
        "# directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "print(train_cats_dir)\n",
        "\n",
        "# directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "print(train_dogs_dir)\n",
        "\n",
        "# directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "print(validation_cats_dir)\n",
        "\n",
        "# directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "print(validation_dogs_dir)\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "print('total training cat images:', num_cats_tr)\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print(\"--\")\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "print('total validation cat images:', num_cats_val)\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "\n",
        "print(\"--\")\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "print(\"Total training images:\", total_train)\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "print(\"Total validation images:\", total_val)\n",
        "\n",
        "# parameter Initialization\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "# 데이터를 시각화하기 위한 함수\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Training data generator\n",
        "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=0.3,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=False)\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "train_data_gen[0][0].shape\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)\n",
        "\n",
        "# Validation data generator\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "sample_training_images, _ = next(val_data_gen)\n",
        "plotImages(sample_training_images[:5])\n",
        "\n",
        "_[:5]\n",
        "\n",
        "# 문제1-1. 이미지에 나온 VGG16 모델을 구현하세요.\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_vgg16():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_vgg16()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "loss_function=tf.keras.losses.binary_crossentropy\n",
        "optimize=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "metric=tf.keras.metrics.binary_accuracy\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimize,\n",
        "              metrics=[metric])\n",
        "\n",
        "# callbacks_list= [tf.keras.callbacks.TensorBoard(log_dir='log_dir', histogram_freq=1)]\n",
        "# callback 함수를 활용하고 싶다면 추가해서 학습하는 데에 활용해 보세요.\n",
        "\n",
        "history = model.fit(\n",
        "      train_data_gen,\n",
        "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_data_gen,\n",
        "      # callbacks=callbacks_list,\n",
        "      validation_freq=1)\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=0.3,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=False)\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "# 문제 1-2. 모델 구현\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def build_optimized_vgg16():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_normal'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_normal'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_optimized_vgg16()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "      train_data_gen,\n",
        "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_data_gen,\n",
        "      # callbacks=callbacks_list,\n",
        "      validation_freq=1)\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    }
  ]
}